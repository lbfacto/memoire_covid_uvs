# -*- coding: utf-8 -*-
"""segmenatation_semenantic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yi56DMuzsipMcBMwcJcJ6IZ3k1pRWgLN
"""



"""**Model de semgmenation avec segmentation_models**"""

from google.colab import drive
drive.mount('/content/drive')

#!pip install -U -q segmentation-models
#!pip install -q tensorflow==2.5.0
#!pip install -q keras==2.5

from tensorflow import keras
import segmentation_models as sm

import tensorflow as tf
import segmentation_models as sm
import glob
import cv2
import os
import numpy as np
from matplotlib import pyplot as plt

#Resizing images is optional, CNNs are ok with large images
SIZE_X = 256 #Resize images (height  = X, width = Y)
SIZE_Y = 256



BACKBONE = 'resnet34'
preprocess_input = sm.get_preprocessing(BACKBONE)

#Capture training image info as a list
train_images = []

for directory_path in glob.glob("/content/drive/MyDrive/Model_Xrays/images"):
    for img_path in glob.glob(os.path.join(directory_path, "*.png")):
        #print(img_path)
        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       
        #img = cv2.resize(img, (SIZE_Y, SIZE_X))
        #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
        train_images.append(img)
        #train_labels.append(label)
#Convert list to array for machine learning processing        
train_images = np.array(train_images)

train_masks = [] 
for directory_path in glob.glob("/content/drive/MyDrive/Model_Xrays/Masks"):
    for mask_path in glob.glob(os.path.join(directory_path, "*.png")):
        mask = cv2.imread(mask_path, 0)       
        #mask = cv2.resize(mask, (SIZE_Y, SIZE_X))
        #mask = cv2.cvtColor(mask, cv2.COLOR_RGB2BGR)
        train_masks.append(mask)
        #train_labels.append(label)
#Convert list to array for machine learning processing          
train_masks = np.array(train_masks)

#Use customary x_train and y_train variables
X = train_images
Y = train_masks
Y = np.expand_dims(Y, axis=3) #May not be necessary.. leftover from previous code

from sklearn.model_selection import train_test_split
x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)

# preprocess input
x_train = preprocess_input(x_train)
x_val = preprocess_input(x_val)

# define model
model = sm.Unet(BACKBONE, encoder_weights='imagenet')
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mse'])

!pip install tensorflow --upgrade
!pip install keras --upgrade

print(model.summary())

history=model.fit(x_train, 
          y_train,
          batch_size=8, 
          epochs=10,
          verbose=1,
          validation_data=(x_val, y_val))

accuracy = model.evaluate(x_val, y_val)

loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'y', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

model.save('membrane1.h5')

from tensorflow import keras
model = keras.models.load_model('membrane1.h5', compile=False)
#Test on a different image
#READ EXTERNAL IMAGE...
test_img = cv2.imread('/content/drive/MyDrive/Memoire covid/dataset_covid/covid/EURyFBbXYAAp3GU.jfif', cv2.IMREAD_COLOR)       
test_img = cv2.resize(test_img, (SIZE_Y, SIZE_X), interpolation=cv2.INTER_AREA)

test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2BGR)
test_img = np.expand_dims(test_img, axis=0)

prediction = model.predict(test_img)

prediction_image = prediction.reshape(mask.shape)
plt.imshow(prediction_image )
plt.imsave('test0_segmented.jpg', prediction_image)